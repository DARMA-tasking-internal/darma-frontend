%!TEX root = ../sandReportSpec.tex

\section{SPMD support}
\label{sec:spmd}
Most applications written in or ported to DARMA will likely have \gls{spmd} as
the dominant form of parallelism.
To simplify the implementation of SPMD-structured codes, the notion of 
a \gls{rank} is maintained within the \gls{API}.   
Again, rather than rely entirely on sequential semantics in cases of massive data parallelism,
many independent parallel execution streams can begin simultaneously and coordinate via the key-value store.
Each execution stream is assigned a unique rank ID, analogous to the MPI rank assigned to processes in a MPI communicator.
The initialization and termination of the runtime in each unit 
is via the calls \inlinecode{darma_init()} and \inlinecode{darma_finalize()}. 
The total number of \gls{spmd} units are queried with the call \inlinecode{darma_spmd_size()},
and the rank is queried with \inlinecode{darma_spmd_rank()}. A typical user 
written main program will look as follows:
\begin{CppCode}
int darma_main(int argc, char**argv){
  darma_init(argc, argv);
  size_t n_ranks = darma_spmd_size();
  size_t me = darma_spmd_rank();
  ...
  darma_finalize();
  return 0;
}
\end{CppCode}

The rank is a very useful concept to orchestrate dependencies in a \gls{spmd}
model since data pertaining to a rank can be associated with keys that utilize
the rank for uniqueness. The example below illustrates this concept, where
the rank is integral to the key associated with data originating on that rank.
\begin{CppCode}
size_t me = darma_spmd_rank();
auto data_handle = initial_access<double>("data_key", me);
\end{CppCode}  
Note that in DARMA, SPMD ranks are actually just a special kind of task that
happens to have a name containing the rank, and can be treated as such. 
However, the similarity to traditional, MPI-style SPMD upon launch should improve the ease of porting and scalability significantly.

We emphasize again that coordinating (rather than communicating) abstracts physical data locations to better support task migration.
Additionally, it removes message-ordering requirements to better support asynchronous data transfers.
We further reiterate that even though the key-value store appears a data store,
it can be implemented in a scalable distributed fashion.

