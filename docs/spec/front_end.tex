%!TEX root = sandReportSpec.tex

\chapter{DARMA Front End API}
\label{chap:front_end}

This chapter describes the DARMA \gls{front end} \gls{API}, 
by introducing the following supported constructs:
\begin{compactitem}
\item Task and Deferred Work Creation
\item Data Access Handles
\item Keyword arguments
\item \gls{spmd} support
\item Serialization Manager
\end{compactitem}
Moreover, we discuss in detail the rules for using the data access handles.


\section{Deferred Work Creation}
\label{sec:deferred}
In DARMA, like other AMT runtime systems, the user creates blocks of work that
are executed when the proper permissions on the data they use are available. 
Deferred work is communicated to the runtime system via the
\inlinecode{create_work()} function, which utilizes the C++ lambda mechanism to
yield the following syntax:
% DSH merged [=]{ into one line for a couple of reasons; chief reason is we may
% want to macro this at some point so that it can conditionally be compiled into
% [=] __cuda_inline__ {  or something like that for GPU use.
\begin{CppCode}
  create_work([=]{
    // work to do
  });
\end{CppCode}

While this syntax leverages \CC11 lambdas, the user does not need to understand
\CC11 standard features to use \inlinecode{create_work()} (this
complexity is managed by DARMA's translation layer, as summarized in
Chapter~\ref{chap:translation_layer}). All the work specified within a
\inlinecode{create_work} is queued for deferred execution, and will be run when
all of its \glspl{dependency} and \glspl{anti-dependency} are met.  
These \glspl{dependency} are determined from the use of 
\inlinecode{AccessHandle<T>} objects in the deferred context. 
\inlinecode{AccessHandle<T>} objects are described in more detail below, in
Section \ref{sec:handles}.  In a basic sense, handles help maintain
\gls{sequential semantics} in the programming model.  For instance, the
following code should print ``first: 42, second: 84'':
\begin{CppCode}
AccessHandle<int> my_handle = initial_access("some_data_key");
create_work([=]{
  my_handle.set_value(42);
});
create_work([=]{
  cout << "first: " << my_handle.get_value();
});
create_work([=]{
  my_handle.set_value(my_handle.get_value()*2);
});
create_work([=]{
  cout << ", second: " << my_handle.get_value();
});
\end{CppCode}
This intuitive way of coding is called \gls{sequential semantics}, 
and its use is pivotal to the DARMA programming model.

% DSH took this out for now
% which manage the complexity necessary (within DARMA's
%\gls{translation layer}) to 1) preserve \gls{sequential semantics} within a \gls{rank}, while performing work asynchronously, and 2) \inlinecode{publish} data visibly outside a \gls{rank}.
%\Glspl{dependency} and \glspl{anti-dependency} for a 
%\inlinecode{create_work} are inferred by the runtime via
%\gls{introspection} (again, within the \gls{translation layer}). 
%The following simple example illustrates how \inlinecode{handles} and
%\inlinecode{create_work} can be used to gether in a simple ``hello world''
%example:
%\begin{CppCode}
%#include <darma.h>
%using namespace darma_runtime;
%using namespace darma_runtime::keyword_arguments_for_publication;
%
%int main(int argc, char** argv) {
%
%  darma_init(argc, argv);
%
%  size_t me = darma_spmd_rank();
%  size_t n_ranks = darma_spmd_size();
%
%  auto greetingMessage = initial_access<std::string>("myName", me);
%
%  create_work([=]
%  {
%    greetingMessage.set_value("hello world!");
%  });
%
%  create_work([=]
%  {
%    std::cout << "DARMA rank " << me << " says " 
%              << greetingMessage.get_value() << std::endl;
%  });
%
%  darma_finalize();
%
%}
%\end{CppCode}
%In this example, 1) the DARMA environment is initialized, 2) each rank creates
%% a task to store a greeting message into a string, and 3) each rank then creates a
%task to print the message and its rank to standard output.
%Note that, in this example, \inlinecode{publish} is not required as the
%dependency \inlinecode{greeting_message} is createed for each rank individually
%(i.e., none of the dependencies must be visible outside of its rank).
%In order to guarantee \gls{sequential semantics} (i.e., to make sure the value
%of \inlinecode{greetingMessage} is set before it is printed),
%\inlinecode{greetingMessage} must be a \inlinecode{handle}.



\section{Data Access Handles}
\label{sec:handles}

% Removed todo for now
%\todo[inline]{JB Question to David/Jeremy: do we need to introduce versions, or
%is this no longer needed? DSH: Versions go with publish(), but some of it needs
%to be here because e.g., read\_access<T>() needs to reference them.}

Transactions with the \gls{key-value store} are conducted using data handles 
that are of different access types which differentiate the various transactions. 
At the most basic level user code can declare 
\begin{enumerate}
\item a handle to data that does not yet exist in the system
but needs to be created, or
\item a handle to data that already exists and needs to
be read, or 
\item a handle to data that it wants to overwrite or modify. 
Note that this type of handle does not exist in the 0.2 version of the spec.
\end{enumerate}

Type 1 is denoted as \inlinecode{initial_access} in DARMA, 
which informs the runtime that the data with the 
specified key does not yet exist, and the user intends to 
create this data and (potentially) publish it.
Hence, an \inlinecode{initial_access} data handle is usually 
followed by a memory allocation, a value assignment and 
finally a publish operation, as illustrated below: 

\begin{CppCode}
auto float_handle = initial_access<float>("float_key");
create_work([=]{
  float_handle.set_value(3.14);
});
\end{CppCode}
The second type of handle, requesting read-only access 
to a piece of data, is via \inlinecode{read_access}. 

%\todo[inline]{This needs to be revised or changed, since
%``wait\_and\_get\_value()'' (or whatever we end up calling it) is an
%advanced feature (and not part of the 0.2 spec).}
%\begin{CppCode}
%auto float_handle = read_access<float>("another_float_key");
%{
%  float val = float_handle.wait_and_get_value();
%  std::cout << "Value read with key another_float_key is " << val;
%}
%\end{CppCode}
%or, alternatively using deferred execution
\begin{CppCode}
auto float_handle = read_access<float>("another_float_key");
create_work([=]{
  float val = float_handle.get_value();
  std::cout << "Value read with key another_float_key is " << val;  
});
\end{CppCode}
%The runtime guarantees that \inlinecode{get_value} will wait until the value
% exists and is ready locally.
You can only call \inlinecode{get_value} in a context where you have read access
to the data associated with the handle, either by capturing into a deferred
context or by explicitly waiting on the value (though waiting on the value is
not supported in the 0.2 spec).
This might involve moving data if the \inlinecode{float} is on a remote node.
In general, any calls to \inlinecode{get_value} should occur 
within a scoped code block to avoid dangling references to stale physical memory locations.
Even when it becomes possible to wait on the data associated with a handle (in
later versions of the spec), best practice is to access data via deferred tasks
inside a \inlinecode{create_work} block when possible.

The third handle type, which informs the runtime that the data 
with the specified key will be read and overwritten or modified, 
is with the \inlinecode{read_write} handle, illustrated below. 
%Again, we show an
%example done within the same task and an example using a deferred task.
%\begin{CppCode}
%auto float_handle = read_write<float>("yet_another_float_key");
%{
%  std::cout << "Value read with key yet_another_float_key is " 
%          << float_handle.get_value();
%  float_handle.set_value(3.14*2.0);
%}
%\end{CppCode}
\begin{CppCode}
auto float_handle = read_write<float>("yet_another_float_key");
create_work([=] {
  std::cout << "Value read with key yet_another_float_key is " 
          << float_handle.get_value();
  float_handle.set_value(3.14*2.0);
});
\end{CppCode}
This sort of access is not available in the 0.2 version of the spec, and in
later versions this sort of usage will be conceptualized as ``ownership
transfer'' of a data block, since exactly one \inlinecode{AccessHandle} with
modification privileges on a block of data can exist at any given time.
%As with \inlinecode{read_access}, value get/set should at least occur within a
% scoped code block, and will likely perform better if placed in a deferred task block.

Tasks should only ever request the privileges they need. 
Over-requesting privileges will limit the amount of available parallelism in the code.
It may occur that the task is using a read-write handle, but needs to create a
task that only requires read access.

\begin{CppCode}
auto float_handle = read_write<float>("yet_another_float_key");
create_work(reads(float_handle), [=] {
  std::cout << "Value read with key yet_another_float_key is " 
          << float_handle.get_value() << std::endl;
})
create_work(reads(float_handle), [=] {
  float val = float_handle.get_value();
  if (val > 0) std::out << "Value is positive" << std::end;
})
//read-write work down here
\end{CppCode}
In this case, subtasks are created that only need read access. 
Without the \inlinecode{reads} qualifier, these tasks would conflict since they
would by default request read-write privileges.

\subsection{Publish}
\label{subsec:publish}
By default, unless explicitly published, data handles are visible only to tasks
within the same scope (that is, tasks that have a copy of the actual
\inlinecode{AccessHandle<T>} object, created as discussed in
Section \ref{sec:handles}.
For data to be globally visible in the global memory space (key-value store),
the application developer must explicitly \inlinecode{publish} data.  Unpublished 
data will be reclaimed once the last handle to it goes out of scope,
freeing the memory and resolving any anti-dependencies analogous to the
destructor invocation in C++ when a class goes out of scope.  Unpublished data
can leverage the sequential semantics of the application for garbage
collection.  Published data, however, is globally visible to all workers and
requires more ``permanence.''  In order to reclaim the data (garbage collect or
resolve anti-dependence), publish data must know its access group.
When all read handles within an access group have been deleted or released
\emph{globally}, the published data can be reclaimed.
The easiest way to declare an access group (and currently supported method) is
to simply give the total number of additional read \inlinecode{AccessHandle<T>}
objects that will be created referring to it.
In future versions, hints will be supported about which specific tasks will need
to read data.
The publish/fetch mechanism replaces an analogous \inlinecode{MPI_Send/Recv} or
even potentially an \inlinecode{MPI_Bcast}.
In MPI, these function calls force an \inlinecode{MPI_Send} or
\inlinecode{MPI_Wait} to block until the runtime guarantees that the data has
been delivered.
An access group in DARMA provides a similar guarantee.
Until all readers in an access group have received or released their data, DARMA
cannot reclaim (garbage collect, clear anti-dependencies).

\begin{CppCode}
auto float_handle = initial_access<float>("float_key");
create_work([=]{
  float_handle.set_value(3.14);
});
float_handle.publish(n_readers=1);
\end{CppCode}
The \inlinecode{n_readers} specification in the publish call is a keyword
argument (see Section \ref{sec:keyword}) that informs the runtime that the data
(associated with \inlinecode{float_key}) will only ever be read once, and hence
can be safely garbage collected soon after.  This code is essentially a direct
replacement of a send/recv.

Publish operations are treated as asynchronous read operations --- that is,
\inlinecode{h.publish(/*...*/)} is treated like
\verb| create_work(reads(h), [=]{/*...*/}); |. 
This means that the same precautions should be taken as with asynchronous reads. 
In particular, even if the handle was in a modifiable state before the 
\inlinecode{publish}, it is no
longer valid to call \lstinline!h.set_value()! after the publish, since the
asynchronous read done by the publish may or may not have occurred yet.  In this
scenario, one should use \verb|create_work([=]{ h.set_value(/*...*/); });|
instead.



\subsubsection{Publication Versions}

If a handle is going to be published multiple times (or, more specifically, if
the key with which the handle was created is going to be published multiple
times), it needs to be published with a different version each time.  Versions
are just like keys --- an arbitrary tuple of values (see Section
\ref{subsec:keys}).  For instance:

\begin{CppCode}
auto float_handle = initial_access<float>("float_key");
auto int_handle = initial_access<int>("int_key");
/*...*/
int_handle.publish(n_readers=3, version=77);
// Use version() instead of version= for multi-part version keys
float_handle.publish(n_readers=1, version("alpha",42));

/* Elsewhere... (e.g., on a different rank) */
auto my_int = read_access<int>("int_key", version=77);
auto my_flt = read_access<float>("float_key", version("alpha",42));

\end{CppCode}

% DSH took this out, since it's supposed to be in 0.3
%\subsection{Subscribe}
%\label{subsec:subscribe}
%\todo[inline]{add subscribe (0.2.1)}

\subsection{Keys}
\label{subsec:keys}
In the examples in this Section, the \inlinecode{key} to the
\inlinecode{AccessHandle<T>} has always been a single string. 
A \inlinecode{key} in DARMA 
can be an arbitrary \gls{tuple} of values.  This 
makes it very easy for the application developer to create an expressive
and descriptive \inlinecode{key} for each piece of data.  Tuples can comprise
different bit-wise copiable data types.  The example at the end of
Section~\ref{sec:spmd} illustrates the use of the \gls{rank} within the handle
\inlinecode{key}.  The following example shows the use of an
aribitrary \gls{tuple} as a \inlinecode{key}:
\begin{CppCode}
  int neighbor_id
  double other_identifier;

  // some code that sets neighborID and other_identifier
  
  auto float_handle = initial_access<float>("float_key", 
                                            neighbor_id, 
                                            other_identifier);
\end{CppCode}


\section{Keyword arguments}
\label{sec:keyword}


Similar to higher-level languages like Python, the DARMA C++ interface allows the user
to specify arguments to many of the API functions and constructs using either positional
or keyword arguments. In addition, many optional arguments may {\em only} be specified using
keyword arguments. The syntax for specifying a keyword argument is identical to that
of Python: \inlinecode{keyword=value}.  For instance, if there is 
a function \inlinecode{some_function} in the DARMA API that accepts 
positional or keyword arguments \inlinecode{arg_a}, 
\inlinecode{count}, and \inlinecode{flag}, that function can be invoked 
equivalently in any of the following ways:
\begin{CppCode}
/* some_function signature:
 *  void some_function(std::string arg_a, int count, bool flag);
 */
// All of the following are equivalent:
some_function("hello", 42, true);
some_function(arg_a="hello", count=42, flag=true);
some_function(count=42, flag=true, arg_a="hello");
some_function("hello", flag=true, count=42);
\end{CppCode}
Note that positional arguments may {\em not} be specified after the first keyword argument,
and an argument cannot be specified more than once, even as a positional and keyword
argument.  Both of these lead to compile-time errors. Omitting a required argument is 
also a compile-time error, as is giving an argument of the incorrect type: 
\begin{CppCode}
// Error: arg_a specified more than once
some_function("hello", 42, true, arg_a="whoops!");

// Error: missing required argument flag
some_function("hello", count=42);

// Error: cannot convert bool to std::string
some_function(arg_a=false, flag=true, count=42);
some_function(false, 42, true);

// Error: positional argument given after first keyword argument
some_function(arg_a="hello", 42, flag=true);
\end{CppCode}
The illusion of Python-like keyword arguments is accomplished 
using \inlinecode{constexpr} instances
of a class with the assignment operator overloaded.  The arguments are passed to the 
callable using perfect forwarding, and thus the overhead from the keyword argument 
trick is entirely at compile-time.  (More implementation details are given in
Section \ref{sec:kwargs}).  These instances are defined in very descriptive namespaces,
and frequently used keywords are aliased into more general namespaces. 
For instance, the keywords for \inlinecode{some_function}, above, would likely be 
defined in a namespace named using the following convention:
\inlinecode{darma::keyword_arguments_for_some_function}.
If \inlinecode{some_function} was a 
widely used construct, its more important keywords would also be defined 
in the namespace \inlinecode{darma::keyword_arguments}. 
If \inlinecode{some_function} belonged to a broader category of 
constructs, certain of its keywords may also be aliased into a 
categorical namespace as well.  For instance, if \inlinecode{some_function} 
implemented some memory management functionality,
its keywords may be aliased into \inlinecode{darma::keyword_arguments_for_memory_management} or 
something.  All of this is done so that the user can minimize verbosity without introducing
naming conflicts.  In certain contexts, it may be expedient for the user to simply
put \inlinecode{using darma::keyword_arguments} at the beginning of the calling context. 
In other, more complicated contexts, importing all DARMA keywords into the 
local context may lead to naming conflicts with local variables. 
You don't have to guess at which namespaces
a keyword is provided in or aliased into; every time a keyword argument or a callable
accepting that argument is introduced in the documentation, the namespace to which 
it belongs and all namespaces it is aliased into are given.

% DSH: removed section and TODO for now.  These are discussed briefly above in
% the handles section anyway.  We can elaborate more there later.
%\subsection{Decorators to create\_work()}
%\label{subsec:decorators}
%\todo[inline]{add information here regarding decorators to create\_work: right
%now we have waits(), reads(), writes(), and reads\_writes()}


\section{SPMD support}
\label{sec:spmd}
% DSH: Removed this TODO.  It's good enough for now.
%\todo[inline]{this section needs to be revised.  Didn't Jeremy already take a
%crack at it?  His changes don't appear to be here\ldots} 
%\gls{spmd} being the
%dominant model of parallelism in DARMA, \todo{are we comfortable saying this like this?  Is it even really true?} the spin-up of the
%runtime in each \gls{spmd} unit is kept analogous to MPI. 
Most applications written in or ported to DARMA will likely have \gls{spmd} as
the dominant form of parallelism.
To simplify the implementation of SPMD-structured codes, the notion of 
a \gls{rank} is maintained within the \gls{API}.   
This should make it a little easier for existing MPI based application codes to transition 
to DARMA. The initialization and termination of the runtime in each unit 
is via the calls \inlinecode{darma_init()} and \inlinecode{darma_finalize()}. 
The total number of \gls{spmd} units are queried with the call \inlinecode{darma_spmd_size()},
and the rank is queried with \inlinecode{darma_spmd_rank()}. A typical user 
written main program will look as follows:
\begin{CppCode}
int main(int argc, char**argv){

	darma_init(argc, argv);
	size_t n_ranks = darma_spmd_size();
	size_t me = darma_spmd_rank();

	//lots of code

	darma_finalize();
}
\end{CppCode}

The rank is a very useful concept to orchestrate dependencies in a \gls{spmd}
model since data pertaining to a rank can be associated with a key that utilize
the rank for uniqueness. Similarly, the unique key used by a different rank
from which data needs to be fetched can be constructed from the knowledge of
the rank creating the data.  The example below illustrates this concept, where
the rank is integral to the key associated with data originating on that rank
\begin{CppCode}
size_t me = darma_spmd_rank();
auto data_handle = initial_access<double>("data_key", me);
\end{CppCode}  
Note that in DARMA, SPMD ranks are actually just a special kind of task that
happens to have a name containing the rank, and can be treated as such. 
However, the similarity to traditional, MPI-style SPMD upon launch will simplify
the learning and porting process significantly.


% DSH: removed section and TODO for now.  These are discussed briefly above in
% the handles section anyway.  We can elaborate more there later.
%\subsection{Decorators}
%\label{subsec:decorators}
%\todo[inline]{add information here regarding decorators to create\_work: right
%now we have waits(), reads(), writes(), and reads\_writes()}


\section{Serialization API}
\todo[inline]{flesh out this section for 0.2.1 or 0.3 (whenever it gets more
settled in the backend API)}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\specialcell}[2][c]{%
  \begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}
\newcommand{\yes}{\text{\ding{51}}}
\newcommand{\no}{\text{\ding{55}}}


\section{Handles Usage Rules}
\todo[inline]{FR: can be moved some other place if more useful}

Handles are assigned states, and these states change 
based on the operations applied to them. In other words, 
handles' states transition. However, not all states 
are allowed at all times. The ``permissions'' on 
what it is allowed changes based on the context. 
Permissions fall under two main categories: 
\begin{itemize}
\item[a] {\it Scheduling}: permissions on a handle 
within a \inlinecode{create_work} (more generally within a deferred work).
\item[b] {\it Immediate}: permissions that apply immediately.
\end{itemize}

In the 0.2 spec, as described above, there are two main types 
of handle supported:
\begin{itemize}
\item \inlinecode{initial_access<T>}: when a handle of 
this type is first created, it is assigned 
``Modify/None'' permissions.
%
\item \inlinecode{read_access<T>}: when a handle of 
this type is first created, it is assigned 
``Read/None'' permissions.
\end{itemize}




\begin{table}[!t]
\begin{center}
{\small
\begin{tabular}{cc|cc|cc|cc}
 \hline
 \multicolumn{2}{c|}{\inlinecode{}}
 & \multicolumn{2}{c|}{\inlinecode{get_value()}} 
 & \multicolumn{2}{c|}
 {
    \specialcell{ \inlinecode{emplace_value()} \\ 
                  \inlinecode{set_value()}\\
                  \inlinecode{get_reference()}\\
                  } 
 } 
 & \multicolumn{2}{c}{\inlinecode{release()}} \\
 \hline
 \specialcell{Scheduling\\ permissions} 
 & \specialcell{Immediate\\ permissions}  
 & { {\footnotesize Allowed? } } \hspace{-0.cm} & { {\footnotesize Continuing as}}
 & { {\footnotesize Allowed? } } \hspace{-0.cm} & { {\footnotesize Continuing as}}
 & { {\footnotesize Allowed? } } \hspace{-0cm} & { {\footnotesize Continuing as }}\\
 \hline
 None & None
 & No & -
 & No & -
 & Yes${}^*$ & {\em None/None} \\
 %
 Read & None
 & No & -
 & No & -
 & Yes & {\em None/None} \\
 %
 Read & Read
 & Yes & {\em Read/Read}
 & No & -
 & Yes & {\em None/None}   \\
 %
 Modify & None
 & No & -
 & No & -
 & Yes & {\em None/None}   \\
 %
 Modify & Read
 & Yes & {\em Modify/Read}  
 & No & -
 & Yes & {\em None/None}   \\
 %
 Modify & Modify
 & Yes & {\em Modify/Modify}  
 & Yes & {\em Modify/Modify}  
 & Yes & {\em None/None}   \\
\hline
\end{tabular}
}
\caption{Operations on the various states. 
Transitions marked with an asterisk (*) effectively
represent no-ops and could generate warnings.}
\label{tab:immsimp}
\end{center}
\end{table}
%
\begin{table}[!t]
\begin{center}
{\small
\begin{tabular}{cc|ccc|ccc}
 \hline
 \multicolumn{2}{c|}{} 
 & \multicolumn{3}{c|}{\em{read-only capture}} 
 & \multicolumn{3}{c}{\em{modify capture}}  \\
 \hline
 \specialcell{Scheduling\\ permissions} 
 & \specialcell{Immediate\\ permissions}  
 & {\footnotesize Allowed? } & {\footnotesize Captured } 
 & {\footnotesize Continuing as} 
 & {\footnotesize Allowed? } & {\footnotesize Captured } 
 & {\footnotesize Continuing as} \\
 \hline
 None & None & No & - & - & No & - & - \\
 %
 Read & None 
 & Yes 
 & {\em Read/Read}
 & {\em Read/None}
 & No
 & -
 & - \\
 %
 Read & Read
 & Yes 
 & {\em Read/Read}
 & {\em Read/Read}
 & No
 & -
 & - \\
 %
 Modify & None
 & Yes 
 & {\em Read/Read}
 & {\em Modify/None}
 & Yes
 & {\em Modify/Modify} 
 & {\em Modify/None} \\
 %
 Modify & Read
 & Yes 
 & {\em Read/Read}
 & {\em Modify/Read}
 & Yes
 & {\em Modify/Modify} 
 & {\em Modify/None} \\
 %
 Modify & Modify
 & Yes 
 & {\em Read/Read} 
 & {\em Modify/Read} 
 & Yes
 & {\em Modify/Modify}
 & {\em Modify/None} \\
\end{tabular}
}
\caption{Deferred (capturing) operations on the various states.}
\label{tab:capsimp}
\end{center}
\end{table}



Example (1): 
\hspace{-0.75cm}
\begin{minipage}[t]{0.45\linewidth}%
\centering
WRONG
\begin{vaspPseudo}
initial_access<int> a
//a is in Modify/None
a.set_value(1) $\no$ 
a.get_value()  $\no$
\end{vaspPseudo}
\end{minipage}
\hspace{0.55cm}
\begin{minipage}[t]{0.45\linewidth}
\centering
CORRECT
\begin{vaspPseudo}
initial_access<int> a
//a is in Modify/None
create_work([=]{ //modify capture
    a.emplace_value(1)  $\yes$
    a.set_value(1)      $\yes$
    a.get_reference()=1 $\yes$
});
\end{vaspPseudo}
\end{minipage}



Example (2): 
\hspace{-0.75cm}
\begin{minipage}[t]{0.45\linewidth}%
\centering
WRONG
\begin{vaspPseudo}
read_access<int> b
//b is in Read/None
b.get_value()   $\no$
b.set_value(1)  $\no$
create_work([=]{ //modify capture
  b.set_value(1) $\no$
});
\end{vaspPseudo}
\end{minipage}
\hspace{0.55cm}
\begin{minipage}[t]{0.45\linewidth}
\centering
CORRECT
\begin{vaspPseudo}
read_access<int> b
//b is in Read/None
create_work([=]{ //modify capture
  b.get_value()  $\yes$
});
\end{vaspPseudo}
\end{minipage}




\clearpage
\section{Basic examples for front end functions}

In this section, we illustrate the basic functionalities of 
the DARMA 0.2 spec using some simple, targeting examples.


\subsection{List of front end functions}

\begin{itemize}
\item \texttt{darma\_init()}
\item \texttt{darma\_finalize()}
\item \texttt{darma\_spmd\_rank}
\item \texttt{darma\_spmd\_size}

\item \texttt{initial\_access<T>}
\item \texttt{create\_work}
\item \texttt{read\_access<T>}

\item \texttt{reads()}
\item \texttt{n\_readers}
\item \texttt{version}

\item \texttt{AccessHandle<T>}
\begin{itemize}
  \item \texttt{publish}
  \item \texttt{get\_value}
  \item \texttt{set\_value}
  \item \texttt{get\_reference}
  \item \texttt{emplace\_value}
  \item \texttt{operator->}
  \item \texttt{get\_key}
  \item \texttt{=0} or \texttt{release}
\end{itemize}
\end{itemize}



\subsection{Initializing/finalizing the environment}

At the base of DARMA, there is the initialization 
of the environment.
\begin{CppCodeNumb}
#include <darma.h>
int darma_main(int argc, char** argv)
{
  using namespace darma_runtime;

  std::cout << "Initializing darma" << std::endl;
  darma_init(argc, argv);

  // code goes here

  std::cout << "Finalizing darma" << std::endl;
  darma_finalize();
  return 0;
}
\end{CppCodeNumb}





\subsection{SPMD concept: rank and size}

\begin{CppCodeNumb}
#include <darma.h>
int darma_main(int argc, char** argv)
{
  using namespace darma_runtime;
  darma_init(argc, argv);

  // get my rank
  const int myRank = darma_spmd_rank();
  // get size 
  const int size = darma_spmd_size();

  std::cout << "Rank " << myRank << "/" << size << std::endl;

  darma_finalize();
  return 0;
}
\end{CppCodeNumb}



\subsection{Handle type 1: \texttt{initial\_access<T>}}

It is important to stress the concept that when data is 
initialized, given the SPMD environment provided by DARMA, 
each rank needs to create a unique label for the data.

\begin{CppCodeNumb}
#include <darma.h>
int darma_main(int argc, char** argv)
{
  using namespace darma_runtime;
  darma_init(argc, argv);
  const int myRank = darma_spmd_rank();
  const int size = darma_spmd_size();

  // this just creates different handles for different types
  // NOTE: data does not exist yet, only handles!
  auto my_handle1 = initial_access<double>("data_key_1", myRank);
  auto my_handle2 = initial_access<int>("data_key_2", myRank);
  auto my_handle3 = initial_access<std::string>("data_key_3", myRank);
  // etc...

  darma_finalize();
  return 0;
}
\end{CppCodeNumb}




\subsection{Arrow operator and task creation}

\begin{CppCodeNumb}
#include <darma.h>
int darma_main(int argc, char** argv)
{
  using namespace darma_runtime;

  darma_init(argc, argv);
  const int myRank = darma_spmd_rank();
  const int size = darma_spmd_size();

  auto my_handle1 = initial_access<std::vector<double>>("data", myRank);

  create_work([=]
  {
    // first, constructs data with default constructor
    my_handle1.emplace_value(0.0); // set to zero

    // operator-> : get access to methods of object pointed to by handle
    my_handle1->resize(4);

    double * vecPtr = my_handle1->data();
    for (int i = 0; i < 4; ++i)
    {
      vecPtr[i] = (double) i + 0.4;
    }

    std::cout << my_handle1->back() << std::endl;
    assert( my_handle1->back() == 3.4 );
  });

  darma_finalize();
  return 0;
}
\end{CppCodeNumb}




\subsection{More on access handle}

\begin{CppCodeNumb}
#include <darma.h>
int darma_main(int argc, char** argv)
{
  using namespace darma_runtime;

  darma_init(argc, argv);
  const int myRank = darma_spmd_rank();
  const int size = darma_spmd_size();

  // this just creates different handles for different types
  // NOTE: data does not exist yet, only handles!
  auto my_handle1 = initial_access<double>("data_key_1", myRank);
  auto my_handle2 = initial_access<std::string>("data_key_3", myRank);

  create_work([=]
  {
    my_handle1.emplace_value(3.3);
    my_handle1.set_value(3.4);
    my_handle1.get_reference() = 3.6;

    // first, constructs data with default constructor
    my_handle1.emplace_value(3.3);
    my_handle2.emplace_value("Sky is blue");

    // get current values pointed to by the handles
    auto h1Val = my_handle1.get_value();
    auto h2Val = my_handle2.get_value();
    std::cout << "After construction: h1Value = " << h1Val << std::endl;
    std::cout << "After construction: h2Value = " << h2Val << std::endl;

    // reset values using set value function
    my_handle1.set_value(6.6);
    my_handle2.set_value("Sky is green");
    std::cout << "After reset: h1Value = " << my_handle1.get_value() << std::endl;
    std::cout << "After reset: h2Value = " << my_handle2.get_value() << std::endl;

    // reset values using reference
    auto & h1r = my_handle1.get_reference();
    auto & h2r = my_handle2.get_reference();
    h1r = 9.9;
    h2r = "Sky is yellow";
    std::cout << "After reset: h1Value = " << my_handle1.get_value() << std::endl;
    std::cout << "After reset: h2Value = " << my_handle2.get_value() << std::endl;

  });

  darma_finalize();
  return 0;
}
\end{CppCodeNumb}




\subsection{Create work with read-only permission on handle}

\begin{CppCodeNumb}
#include <darma.h>
int darma_main(int argc, char** argv)
{
  using namespace darma_runtime;

  darma_init(argc, argv);
  const int myRank = darma_spmd_rank();
  const int size = darma_spmd_size();

  auto my_handle = initial_access<double>("data", myRank);
  create_work([=]
  {
    my_handle.emplace_value(0.55);
  });

  create_work(reads(my_handle),[=]
  {
    std::cout << " " << my_handle.get_value() << std::endl;
  });

  darma_finalize();
  return 0;
}
\end{CppCodeNumb}






\subsection{Publish and read access}

\begin{CppCodeNumb}
#include <darma.h>
int darma_main(int argc, char** argv)
{
  using namespace darma_runtime;
  using namespace darma_runtime::keyword_arguments_for_publication;

  darma_init(argc, argv);
  const int myRank = darma_spmd_rank();
  const int size = darma_spmd_size();

  // supposed to be run with 2 ranks, so ignore the rest
  assert(size>=2);
  if (myRank>=2){
    darma_finalize();
    return 0;
  }

  // rank0 reads from source = rank1 
  // rank1 reads from source = rank0 
  int source = myRank==0 ? 1 : 0;

  auto my_handle = initial_access<double>("data", myRank);
  create_work([=]
  {
    my_handle.emplace_value(0.5 + (double) myRank);

    // n_readers == 1 because: 
    //  rank0 reads data of rank1
    //  rank1 reads data of rank0
    my_handle.publish(n_readers=1);
  });

  AccessHandle<double> readHandle = read_access<double>("data", source);
  create_work([=]
  {
    std::cout << myRank << " " << readHandle.get_value() << std::endl;
    if (myRank==0)
      assert( readHandle.get_value() == 1.5 );
    else
      assert( readHandle.get_value() == 0.5 );
  });

  darma_finalize();
  return 0;
}
\end{CppCodeNumb}






\subsection{Publish, versioning and lifetime of handles}

Lifetime of handles is tricky, particularly for \texttt{read\_access<T>()} handle.  
In the following example, we initialize data, publish it, fetch it from another rank, 
modify the data, publish it again under a new version, and then fetch the new version from another rank. 
The \texttt{create\_work} on lines $40-44$ can't execute until the backend knows you're done with the first fetched version. 
We put an extra set of \texttt{\{ \}} around the readaccess+creatework in lines $28-36$ to tell the backend that 
the \texttt{readHandle} is no longer needed and can go out-of-scope and the fetching is done.  
Without the scoping \texttt{\{\}}, the code would deadlock. THis is because the backend would not know that 
the fetching is done until after \texttt{darma\_finalize()} is called. However, \texttt{darma\_finalize()} 
can't return until after {\it all} the \texttt{create\_works} have completed.  And so the code would deadlock. 


\begin{CppCodeNumb}
#include <darma.h>
int darma_main(int argc, char** argv)
{
  using namespace darma_runtime; 
  using namespace darma_runtime::keyword_arguments_for_publication;
  darma_init(argc, argv);
  const int myRank = darma_spmd_rank();
  const int size = darma_spmd_size();

  // supposed to be run with 2 ranks, so ignore the rest
  assert(size>=2);
  // rank0 reads from source = rank1, rank1 reads from source = rank0 
  int source = myRank==0 ? 1 : 0;

  // create data
  auto my_handle = initial_access<double>("data", myRank);
  create_work([=]
  {
    my_handle.emplace_value(0.5 + (double) myRank);
    my_handle.publish(n_readers=1,version=0); // n_readers == 1
  });

  /* scope {} needed here and useful because it tells backend that 
     readHandle will go outofscope and so backend has more detailed 
     info and this can benefit parallelism and execution. 
     In other words, one should scope things whenever it is possible. */ 
  {
    auto readHandle = read_access<double>("data", source,version=0);
    create_work([=]
    {
      std::cout << myRank << " " << readHandle.get_value() << std::endl;
      if (myRank==0)
        assert( readHandle.get_value() == 1.5 );
      else
        assert( readHandle.get_value() == 0.5 );
    });
  }

  // reset value and update version
  create_work([=]
  {
    my_handle.set_value(2.5 + (double) myRank);
    my_handle.publish(n_readers=1,version=1);
  });

  // second time reading
  auto readHandle2 = read_access<double>("data", source,version=1);
  create_work([=]
  {
    std::cout << myRank << " " << readHandle2.get_value() << std::endl;
    if (myRank==0)
      assert( readHandle2.get_value() == 3.5 );
    else
      assert( readHandle2.get_value() == 2.5 );
  });

  darma_finalize();
  return 0;
}
\end{CppCodeNumb}








