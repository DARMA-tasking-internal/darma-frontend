\todo[inline]{Note the use of the type keyword in the glossary entries. We can use this to create subglossaries according to topic.  Right now, everything is just going to a single main glossary. We should think about whether or not we want subglossaries, and if so, how we would like to structure these.}

\todo[inline]{Throughout glossaries and text, make sure usage of concurrency and
  parallelism are consistent and correct.}
\todo[inline]{Figure out how to make inlinecode and gls play nice together in latex,
  then update text accordingly}
\todo[inline]{Make a pass to add text to glossary where appropriate}
\todo[inline]{Consistency check: DARMA/DARMA}

\chapter{Introduction}
\label{chap:introduction}
As we look ahead to next generation platforms and exascale computing,  hardware 
will be characterized by dynamic behavior, increased
heterogeneity, and a marked increase in overall system \gls{concurrency}~\cite{doe_arch, dav_exascale}. 
In order to extract maximal performance from these new architecutres,
alternative programming  and \glspl{execution model}, such as the \gls{AMT
model} are increasingly being explored by the HPC community.  These models break from the dominant
\gls{CSP} or \gls{spmd} models in use today. 



%An \gls{AMT} \gls{programming model} decomposes applications into small, transferable units of work (many tasks) with associated inputs (dependencies or data blocks) rather than simply decomposing at the process level (MPI ranks).
%An \gls{AMT} \gls{execution model} can be viewed as the coarse-grained, distributed memory analog of instruction-level parallelism, extending the concepts of data prefetching,
%out-of-order task execution based on dependency analysis, and even branch prediction (speculative execution). 
%Rather than executing in a well-defined order, tasks execute when inputs become available.

An \gls{AMT} model aims to leverage all available \gls{task parallelism} and
\gls{pipeline parallelism}, rather just relying on basic \gls{data
  parallelism} for \gls{concurrency}.
The term asynchronous encompasses the idea that 1) processes (threads) can
  diverge to different tasks, rather than executing in the same order; and 2)
  \gls{concurrency} is maximized (minimum synchronization) by leveraging
  multiple forms of \gls{parallelism}.
	The term many-task encompasses the idea that the application is decomposed
  into many \emph{transferable} or \emph{migratable} units of work, to
  enable the overlap of communication and computation as well as asynchronous load balancing strategies.  


The \gls{AMT} \gls{runtime system} research community is quite active, with many efforts being
explored~\cite{OCR,STAPL,Legion,StencilHPX,Charm++,Uintah, Loci}.
Each effort represents a different design point within the design space of AMT
models and span different ranges of the software stack.  

In addition to the \gls{AMT} research, there are a number of 
research efforts focused on mitigating exascale architectural targeted research challenges 
within a portion the software stack.  These include, for example, efforts to 1) compile-time
generate performance portable code across a variety of memory and execution
abstractions~\cite{Kokkos, RAJA}, 2) provide lower-level resource management
and aribtration services~\cite{Qthreads, Hobbs, Kitten}, or 3) provide data and
I/O abstractions~\cite{Kelpie, Nessie, Adios, DataSpaces, LLNLandLANLDW}.  These more narrowly focused research efforts often have largely stemmed from projects that
assumed a \gls{CSP}/\gls{MPI} based runtime system.  However, their research is
typically applicable and complementarty to the work being done within the
\gls{AMT} community. 

  
In this document we provide the specification for DARMA,
a programming model, intended as a community-based research vehicle to support AMT programming models and runtime
systems co-design. 
The \gls{API} will evolve quite a bit as its design and specification is comprehensively vetted over
the course of 2016 with teams whose expertise spans the software stack,
including application
developers, \gls{AMT} runtime community, as well as feedback from
research groups focused on specific components of the \gls{HPC} software stack.

This document captures version 0.2 of the specification, in which we 
specify several key features of the DARMA programming model. The features
described in 0.2 are not comprehensive, meaning they do not capture all of the
application requirements that are driving DARMA's design philosopy. 
However, there are several benefits of formalizing a specification very early in the
design process:
\begin{compactenum}
\item Experimenting with the \gls{API} provides an agile method for application
developers to reason about \gls{API} and runtime system requirements,
\item The evolution of the specification provides a vehicle for us to track the
design 
\gls{API} is fixing a separating
policy from mechanism, 
\item It provides an opportunity to introduce abstractions 
being presented across a variety of AMT
\item It facilitates communication of requiremetns to existing AMT runtime
systems,
\end{compactenum}
The common 



DARMA is implemented as an \gls{EDSL} in \CC.
It inherits the generic language constructs of \CC, and adds 
\gls{semantics} that facilitate distributed parallel programming via the
higher-level abstractions presented in this document. 
DARMA comprises three main layers: the \gls{front end}, \gls{middle end}, and
\gls{back end}.  The \gls{front end} is the user-level \gls{API}.  The
\gls{middle end} is a library that heavily leverages \CC \gls{template metaprogramming} 
to translate to a series of \gls{back end} abstract classes that must be
implemented to support the runtime.



From a design-space perspective: application developers across a variety of domains have a strong voice in
shaping the \gls{API}.  This documment will capture the provenance of design
decisions, along with design requests and general application requirements that
drive the various design decisions made.
In DARMA \gls{spmd} is the dominant parallelism and the notion of a \gls{rank}
is maintained within the \gls{API}.   
  The DARMA \gls{API} simplifies the introduction
  of asynchronous task parallelism via the use of standard \CC\ constructs, such
  as \gls{reference counted pointers} and \glspl{lambda}.

As such we expect that the \gls{API} will evolve quite a bit in 2016.  as we seek
community feedback

It provides a mechanism for:



It is intended for use in co-design, and the formal
specification effort is intended to facilitate a community-based approach for
sharing information.











\section{Scope}
\label{sec:scope}
The \gls{API} is being \gls{co-design}ed with application developers
and computer scientists whose knowledge spans the entire runtime software stack.
Current applications affecting the design include portions of the \gls{Trilinos} software stack
and \gls{ASC} \gls{ATDM} efforts at Sandia National Laboratories. 
 


This specification covers user-directed parallelization, where the user
has annotated that portions of the work could be performed asynchronously.
The DARMA runtime will schedule all asynchronous work in a \gls{deferred} fashion,
checking that all \gls{input dependencies} are met prior to performing work.  
The user is responsible for ensuring that the application using the DARMA
\gls{API} constructs executes correctly.


The DARMA \gls{middle end} requires \CC features supported by the \CC14
standard, and will work with the following compilers: \inlinecode{gcc >= 4.7, clang >= 3.5}.

\input{execution_model}

\input{memory_model}

\input{data_model}



\section{Document organization}
\label{sec:organization}
This docuemnt is organized as follows.  In Chapter~\ref{chap:front_end} we
introduce the \gls{front end} \gls{API}.  In Chapter~\ref{chap:middle_end} we
provide a description of the \gls{middle end} translation layer, and in
Chapter~\ref{chap:back_end} we provide the specifics regarding what must be
supproted by each of the \gls{back end} abstract classes in order to implement
the DARMA runtime. In Chapter~\ref{chap:examples} we provide a series of
examples that illustrate usage of the \gls{API}. The DARMA specification is
undergoing rapid development and evolution during the calendar year 2016.  
We conclude this document with
Chapter~\ref{chap:evolution}, which includes a brief history of changes between
previous versions of the specificaiton, along with a list of the planned changes the
in upcoming versions.

